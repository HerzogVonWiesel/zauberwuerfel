{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 09:11:34.558917: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import gymnasium as gym\n",
    "import gym_rubiks\n",
    "from gym_rubiks.rubiks_gym_agent import RubiksAgent\n",
    "from rubiks import RubiksCube\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# stable-baselines3 Reinformencement Learning agent\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"RubiksCube-v0\", cube=RubiksCube(), n_shuffle=1)\n",
    "env = gym.wrappers.TimeLimit(env, max_episode_steps=10)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=0, tensorboard_log=\"./RubiksLog\")\n",
    "# Train the agent and display a progress bar, tensorboard\n",
    "\n",
    "model.learn(total_timesteps=int(6e4), progress_bar=False, tb_log_name=\"./RubiksLog\", log_interval=1)\n",
    "# Save the agent\n",
    "model.save(\"RubiksCube\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"RubiksCube-v0\", cube=RubiksCube(), n_shuffle=2)\n",
    "env = gym.wrappers.TimeLimit(env, max_episode_steps=10)\n",
    "model = PPO.load(\"RubiksCube\", env=env, tensorboard_log=\"./RubiksLog\")\n",
    "\n",
    "model.learn(total_timesteps=int(2e5), progress_bar=False, tb_log_name=\"./RubiksLog_2\", log_interval=1)\n",
    "# Save the agent\n",
    "model.save(\"RubiksCube_2\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"RubiksCube-v0\", cube=RubiksCube(), n_shuffle=3)\n",
    "env = gym.wrappers.TimeLimit(env, max_episode_steps=10)\n",
    "model = PPO.load(\"RubiksCube_2\", env=env, tensorboard_log=\"./RubiksLog\")\n",
    "\n",
    "model.learn(total_timesteps=int(4e5), progress_bar=False, tb_log_name=\"./RubiksLog_3\", log_interval=1)\n",
    "# Save the agent\n",
    "model.save(\"RubiksCube_3\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"RubiksCube-v0\", cube=RubiksCube(), n_shuffle=4)\n",
    "env = gym.wrappers.TimeLimit(env, max_episode_steps=10)\n",
    "model = PPO.load(\"RubiksCube_3\", env=env, tensorboard_log=\"./RubiksLog\")\n",
    "\n",
    "model.learn(total_timesteps=int(8e5), progress_bar=False, tb_log_name=\"./RubiksLog_4\", log_interval=1)\n",
    "# Save the agent\n",
    "model.save(\"RubiksCube_4\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Solved ratio: 753/1000\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Solved ratio: 753/1000\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PPO.load(\"RubiksCube_4\", env=env)\n",
    "\n",
    "vec_env = model.get_env()\n",
    "solved_ratio = 0\n",
    "repeats = 1000\n",
    "for evaluation in range(repeats):\n",
    "    obs = vec_env.reset()\n",
    "    #print(\"-------------------\")\n",
    "    #vec_env.env_method(method_name='print_state', indices=0)\n",
    "    #print(vec_env.get_attr(\"state\"))\n",
    "    #vec_env.env_method(method_name='print_step')\n",
    "    for i in range(10):\n",
    "        #vec_env.env_method(method_name='pprint_state', indices=0)\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        #print(action)\n",
    "        obs, rewards, dones, info = vec_env.step(action)\n",
    "        if rewards[0] == 100:\n",
    "            solved_ratio += 1\n",
    "            #print(rewards)\n",
    "            break\n",
    "print(f\"Solved ratio: {solved_ratio}/{repeats}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
